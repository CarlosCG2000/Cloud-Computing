{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"PlayFramework: deploying to the Cloud","text":"<p>The goal of this section is to teach the students how to deploy their Play applications to the Cloud. We will learn how to deploy our application to AWS, levaraging the RDS service to store our data, performing a fault-tolerant and scalable deployment. We will also learn how to use tools like Packer and Terraform to automate the deployment of our application.</p>"},{"location":"about/","title":"Personal information","text":"<p>My name is Miguel \u00c1ngel Pastor Olivar, a proud dad of three kids, and husband, who happens to work in the software world. Passionate reader, chef aficionado, former surf player, and current cyclist and runner amateur.</p> <p>I am unsuccessfully pursuing to move my PhD research forward.</p> <p>I am currently working as a Staff Engineer at GitHub as a member of their platform and infrastructure team.</p>"},{"location":"about/#email","title":"Email","text":"<p>You can reach me at mapastorol@upsa.es or miguelinlas3@gmail.com</p>"},{"location":"about/#social-networks","title":"Social networks","text":"<p>I use Twitter and Bluesky more than I should. You will find tech-related stuff and some occasional rants about a few different topics: Bsky and Twitter.</p>"},{"location":"about/#github","title":"GitHub","text":"<p>In my GitHub profile you can find what things I\u2019ve been working on (and the source code of this webpage as well).</p>"},{"location":"automated/intro/","title":"A practical example","text":"<p>Transitioning from manual deployment to a structured Infrastructure as Code approach requires careful navigation through a complex landscape of tools and methodologies. While the ecosystem of infrastructure management is vast and intricate, our strategy focuses on a pragmatic, straightforward path that leverages our existing knowledge and minimizes unnecessary complexity.</p> <p>We've chosen an immutable deployment strategy that combines two powerful tools: Packer for server templating and Terraform for provisioning. This approach offers a strategic balance between simplicity and effectiveness, allowing us to modernize our infrastructure management without overwhelming our team with unnecessary complexity.</p> <p>Packer and Terraform present an ideal entry point for our Infrastructure as Code journey. These client-only applications integrate seamlessly with our existing virtual machine infrastructure, requiring no additional complex setup. By building upon our familiar VM environment, we reduce the learning curve and implementation friction.</p> <p>Our chosen approach does come with limitations. More advanced deployment strategies like blue-green deployments will be more challenging to implement. However, for our immediate goals, this method provides a robust, manageable solution that significantly improves our infrastructure consistency and repeatability.</p> <p>This strategy represents more than a technological upgrade\u2014it's a calculated step towards more predictable, reproducible, and manageable infrastructure, setting the foundation for future scalability and innovation.</p>"},{"location":"automated/packer/","title":"Image creation with Packer","text":"<p>The first we need to do to automate our infrastructure is to create a base image. This image will be used to create new servers, and it will contain all the necessary software and configurations to run our application. We will basically replicate the manual process we did in the previous chapter, but in an automated way.</p>"},{"location":"automated/packer/#installing-packer","title":"Installing Packer","text":"<p>You can find here how to install Packer in your OS: Install Packer</p>"},{"location":"automated/packer/#creating-a-packer-script","title":"Creating a Packer script","text":"<p>Packer scripts are written in HCL (https://github.com/hashicorp/hcl). Let's start backwards, defining a fully functional Packer script and then explaining each part.</p> <pre><code>packer {\n  required_plugins {\n    amazon = {\n      source  = \"github.com/hashicorp/amazon\"\n      version = \"~&gt; 1.0\"\n    }\n  }\n}\n\nvariable \"aws_access_key\" {\n  type    = string\n  default = \"\"\n}\n\nvariable \"aws_secret_key\" {\n  type    = string\n  default = \"\"\n}\n\nvariable \"agenda_version\" {\n  type    = string\n  default = \"1.0-SNAPSHOT\"\n}\n\nsource \"amazon-ebs\" \"ubuntu-agenda\" {\n  access_key    = var.aws_access_key\n  secret_key    = var.aws_secret_key\n  region        = \"eu-south-2\"\n  source_ami    = \"ami-01d67cc599f23990b\"\n  instance_type = \"t3.micro\"\n  ssh_username  = \"ubuntu\"\n  ami_name      = \"agenda-app-${var.agenda_version}\"\n  tags = {\n    Version = \"${var.agenda_version}\"\n  }\n}\n\n\nbuild {\n  sources = [\"source.amazon-ebs.ubuntu-agenda\"]\n\n  provisioner \"file\" {\n    source      = \"agenda.service\"\n    destination = \"/home/ubuntu/\"\n  }\n\n  provisioner \"file\" {\n    source      = \"../target/universal/agenda-${var.agenda_version}.zip\"\n    destination = \"/home/ubuntu/agenda.zip\"\n  }\n\n  provisioner \"shell\" {\n    inline = [\n      \"sleep 30\",\n      \"sudo apt-get update\",\n      \"sudo apt install -y openjdk-17-jdk-headless unzip\",\n      \"unzip /home/ubuntu/agenda.zip\",\n      \"sudo mv /home/ubuntu/agenda-${var.agenda_version} /home/ubuntu/agenda\",\n      \"sudo cp /home/ubuntu/agenda.service /etc/systemd/system\",\n      \"sudo systemctl daemon-reload\",\n      \"sudo systemctl enable agenda.service\"\n    ]\n  }\n}\n</code></pre>"},{"location":"automated/packer/#understanding-the-packer-script","title":"Understanding the Packer script","text":"<p>THe Packer script is divided into three main sections: <code>packer</code>, <code>variables</code>, and <code>build</code>.</p>"},{"location":"automated/packer/#required-plugins","title":"Required plugins","text":"<p>The first bits of the script with the <code>packer</code> section and the <code>variable</code> areis used to define the required plugins for the script. In this case, we are using the <code>amazon</code> plugin since we are going to create an AMI in AWS.</p> <pre><code>packer {\n  required_plugins {\n    amazon = {\n      source  = \"github.com/hashicorp/amazon\"\n      version = \"~&gt; 1.0\"\n    }\n  }\n}\n\nvariable \"aws_access_key\" {\n  type    = string\n  default = \"\"\n}\n\nvariable \"aws_secret_key\" {\n  type    = string\n  default = \"\"\n}\n\nvariable \"agenda_version\" {\n  type    = string\n  default = \"1.0-SNAPSHOT\"\n}\n</code></pre>"},{"location":"automated/packer/#the-build-section","title":"The build section","text":"<p>In the build section we find two main parts: the <code>source</code> and the <code>provisioners</code>. The former defines the source of the image we are going to use to create the new image. In this case, we are using an Ubuntu image from AWS.</p> <pre><code>source \"amazon-ebs\" \"ubuntu-agenda\" {\n  access_key    = var.aws_access_key\n  secret_key    = var.aws_secret_key\n  region        = \"eu-south-2\"\n  source_ami    = \"ami-01d67cc599f23990b\"\n  instance_type = \"t3.micro\"\n  ssh_username  = \"ubuntu\"\n  ami_name      = \"agenda-app-${var.agenda_version}\"\n  tags = {\n    Version = \"${var.agenda_version}\"\n  }\n}\n</code></pre> <p>The <code>provisioners</code> section defines the steps we need to follow to configure the image. In this case, we are copying a service file and the application zip file to the server, installing Java, unzipping the application, and configuring the service to start at boot.</p> <pre><code>  provisioner \"file\" {\n    source      = \"agenda.service\"\n    destination = \"/home/ubuntu/\"\n  }\n\n  provisioner \"file\" {\n    source      = \"../target/universal/agenda-${var.agenda_version}.zip\"\n    destination = \"/home/ubuntu/agenda.zip\"\n  }\n\n  provisioner \"shell\" {\n    inline = [\n      \"sleep 30\",\n      \"sudo apt-get update\",\n      \"sudo apt install -y openjdk-17-jdk-headless unzip\",\n      \"unzip /home/ubuntu/agenda.zip\",\n      \"sudo mv /home/ubuntu/agenda-${var.agenda_version} /home/ubuntu/agenda\",\n      \"sudo cp /home/ubuntu/agenda.service /etc/systemd/system\",\n      \"sudo systemctl daemon-reload\",\n      \"sudo systemctl enable agenda.service\"\n    ]\n  }\n</code></pre> <p>Packer has a lot of provisioners that can be used to configure the image. Setting up our application is relatively simple, so the <code>shell</code> and <code>file</code> provisioners are enough.</p>"},{"location":"automated/packer/#executing-the-packer-script","title":"Executing the Packer script","text":"<p>The first thing we need to do is to init the Packer script. From the deploy <code>folder</code>, run:</p> <pre><code>packer init .\n</code></pre> <p>It will download the necessary plugins to run the script.</p> <p>The script provided has been already formatted, but, if you need it, you can run:</p> <pre><code>packer fmt .\n</code></pre> <p>that will format the script for readability and consistency. Packer will print out the names of the files it modified, if any.</p> <p>Before executing the script, you can validate it with:</p> <pre><code>packer validate .\n</code></pre> <p>Before we actually run the build process, note that we need to provide the AWS credentials to Packer. You can do it by setting the environment variables:</p> <pre><code>export AWS_ACCESS_KEY_ID=your_access_key\nexport AWS_SECRET_ACCESS_KEY=your_secret_key\n</code></pre> <p>Now, you can finally build your AMI:</p> <pre><code>packer build agenda.pkr.hcl\n</code></pre>"},{"location":"automated/terraform/","title":"Deploy automation with Terraform","text":"<p>In the previous section, we learned how to create an AMI with Packer. Now, we are going to learn how to deploy our application to AWS using Terraform. The idea is to create a fully automated deployment process, where we can create the infrastructure and deploy our application with a single command.</p> <p>The architecture is the same as the one we used during the whole course, the only difference is that we are going to build a repeatable and automated process to deploy it. Please, note that this application uses an in-memory database, so it is not suitable for production. Automating the generation of an RDS instance and connecting it to the application is left as an exercise that needs to be done by the students as part of the final project that needs to be delivered at the end of the course.</p>"},{"location":"automated/terraform/#installing-terraform","title":"Installing Terraform","text":"<p>You can find here how to install Terraform in your OS: Install Terraform</p>"},{"location":"automated/terraform/#creating-a-terraform-script","title":"Creating a Terraform script","text":"<p>Terraform scripts are written in HCL (https://github.com/hashicorp/hcl). Similar to what we did in the Packer section, let's start backwards, defining a fully functional Terraform script and then explaining each part.</p> <pre><code>variable \"ami_id\" {\n  type    = string\n  default = \"\"\n}\n\nprovider \"aws\" {\n  region = \"eu-south-2\"\n  skip_region_validation = true\n}\n\ndata \"aws_vpc\" \"default\" {\n  default = true\n}\n\ndata \"aws_subnets\" \"default\" {\n  filter {\n    name   = \"vpc-id\"\n    values = [data.aws_vpc.default.id]\n }\n}\n\nresource \"aws_security_group\" \"instance\" {\n  name = \"agenda\"\n\n  ingress {\n    from_port = 80\n    to_port = 80\n    protocol = \"tcp\"\n    security_groups = [aws_security_group.agenda_alb.id]\n  }\n}\n\nresource \"aws_launch_template\" \"agenda\" {\n  name          = \"agenda-template\"\n  image_id      = var.ami_id\n  instance_type = \"t3.micro\"\n  key_name = \"mimo-cloud-teacher\"\n  block_device_mappings {\n    device_name = \"/dev/sda1\"\n    ebs {\n      volume_size = 20\n      volume_type = \"gp2\"\n    }\n  }\n\n  network_interfaces {\n    associate_public_ip_address = true\n    security_groups = [aws_security_group.instance.id]\n  }\n\n  tag_specifications {\n    resource_type = \"instance\"\n    tags = {\n      Name = \"agenda-app\"\n    }\n  }\n}\n\nresource \"aws_autoscaling_group\" \"agenda_asg\" {\n  launch_template {\n    id      = aws_launch_template.agenda.id\n  }\n  vpc_zone_identifier = data.aws_subnets.default.ids\n\n  target_group_arns = [aws_lb_target_group.agenda_tg.arn]\n  health_check_type = \"ELB\"\n\n  min_size = 2\n  desired_capacity = 3\n  max_size = 6\n\n  tag {\n    key = \"Name\"\n    value = \"agenda-asg\"\n    propagate_at_launch = true\n  }\n}\n\nresource \"aws_lb\" \"agenda_lb\" {\n  name = \"agenda\"\n  load_balancer_type = \"application\"\n  subnets = data.aws_subnets.default.ids\n  security_groups = [aws_security_group.agenda_alb.id]\n}\n\nresource \"aws_lb_listener\" \"http\" {\n  load_balancer_arn = aws_lb.agenda_lb.arn\n  port = 80\n  protocol = \"HTTP\"\n\n  default_action {\n    type = \"fixed-response\"\n\n    fixed_response {\n      content_type = \"text/plain\"\n      message_body = \"Page Not Found\"\n      status_code = 404\n    }\n  }\n}\n\nresource \"aws_security_group\" \"agenda_alb\" {\n  name = \"agenda-alb\"\n\n  ingress {\n    from_port = 80\n    to_port = 80\n    protocol = \"tcp\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n  }\n\n  egress {\n      from_port = 0\n      to_port = 0\n      protocol = \"-1\"\n      cidr_blocks = [\"0.0.0.0/0\"]\n  }\n}\n\nresource \"aws_lb_target_group\" \"agenda_tg\" {\n  name = \"agenda-tg\"\n  port = 80\n  protocol = \"HTTP\"\n  vpc_id = data.aws_vpc.default.id\n\n  health_check {\n    path = \"/health\"\n    protocol = \"HTTP\"\n    matcher = \"200\"\n    interval = 15\n    timeout = 5\n    healthy_threshold = 3\n    unhealthy_threshold = 3\n  }\n}\n\nresource \"aws_lb_listener_rule\" \"asg\" {\n  listener_arn = aws_lb_listener.http.arn\n  priority = 100\n\n  condition {\n    path_pattern {\n      values = [\"*\"]\n    }\n  }\n\n  action {\n    type = \"forward\"\n    target_group_arn = aws_lb_target_group.agenda_tg.arn\n  }\n}\n\noutput \"agenda_alb_dns_name\" {\n  value = aws_lb.agenda_lb\n  description = \"Domain name of the Agenda App ALB\"\n}\n</code></pre>"},{"location":"automated/terraform/#understanding-the-terraform-script","title":"Understanding the Terraform script","text":""},{"location":"automated/terraform/#providers","title":"Providers","text":"<p>The first part of the script defines the provider we are going to use. In this case, we are using AWS, so we define the provider as follows:</p> <pre><code>provider \"aws\" {\n  region = \"eu-south-2\"\n  skip_region_validation = true\n}\n</code></pre> <p>Terraform has different providers implementations covering a wide range of cloud providers and services. You can find more information about the providers in the documentation: Terraform Providers</p>"},{"location":"automated/terraform/#defining-the-instances","title":"Defining the instances","text":"<p>Now that we have the provider defined, we can start defining the different resources we need to create. The first one is the security group for the instances and the instances themselves.</p> <pre><code>resource \"aws_security_group\" \"instance\" {\n  name = \"agenda\"\n\n  ingress {\n    from_port = 80\n    to_port = 80\n    protocol = \"tcp\"\n    security_groups = [aws_security_group.agenda_alb.id]\n  }\n}\n\nresource \"aws_launch_template\" \"agenda\" {\n  name          = \"agenda-template\"\n  image_id      = var.ami_id\n  instance_type = \"t3.micro\"\n  key_name = \"mimo-cloud-teacher\"\n  block_device_mappings {\n    device_name = \"/dev/sda1\"\n    ebs {\n      volume_size = 20\n      volume_type = \"gp2\"\n    }\n  }\n\n  network_interfaces {\n    associate_public_ip_address = true\n    security_groups = [aws_security_group.instance.id]\n  }\n\n  tag_specifications {\n    resource_type = \"instance\"\n    tags = {\n      Name = \"agenda-app\"\n    }\n  }\n}\n\nresource \"aws_autoscaling_group\" \"agenda_asg\" {\n  launch_template {\n    id      = aws_launch_template.agenda.id\n  }\n  vpc_zone_identifier = data.aws_subnets.default.ids\n\n  target_group_arns = [aws_lb_target_group.agenda_tg.arn]\n  health_check_type = \"ELB\"\n\n  min_size = 2\n  desired_capacity = 3\n  max_size = 6\n\n  tag {\n    key = \"Name\"\n    value = \"agenda-asg\"\n    propagate_at_launch = true\n  }\n}\n</code></pre> <p>We are basically defining the security group for the instances, the launch template, and the autoscaling group. The autoscaling group will create instances based on the launch template and will register them in. This way, we can have a dynamic number of instances running our application.</p> <p>As you can see, this is the same architecture we manually created in the previous sections. The difference is that now we are automating the process, being able to have a fully functional envrironment using a repeatable and less error-prone process.</p>"},{"location":"automated/terraform/#creating-the-load-balancer","title":"Creating the load balancer","text":"<p>Now that we have the instances, we need to create a load balancer to distribute the traffic among them. The following code creates the load balancer, the target group, and the listener rules.</p> <pre><code>resource \"aws_lb\" \"agenda_lb\" {\n  name = \"agenda\"\n  load_balancer_type = \"application\"\n  subnets = data.aws_subnets.default.ids\n  security_groups = [aws_security_group.agenda_alb.id]\n}\n\nresource \"aws_lb_listener\" \"http\" {\n  load_balancer_arn = aws_lb.agenda_lb.arn\n  port = 80\n  protocol = \"HTTP\"\n\n  default_action {\n    type = \"fixed-response\"\n\n    fixed_response {\n      content_type = \"text/plain\"\n      message_body = \"Page Not Found\"\n      status_code = 404\n    }\n  }\n}\n\nresource \"aws_security_group\" \"agenda_alb\" {\n  name = \"agenda-alb\"\n\n  ingress {\n    from_port = 80\n    to_port = 80\n    protocol = \"tcp\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n  }\n\n  egress {\n      from_port = 0\n      to_port = 0\n      protocol = \"-1\"\n      cidr_blocks = [\"0.0.0.0/0\"]\n  }\n}\n\nresource \"aws_lb_target_group\" \"agenda_tg\" {\n  name = \"agenda-tg\"\n  port = 80\n  protocol = \"HTTP\"\n  vpc_id = data.aws_vpc.default.id\n\n  health_check {\n    path = \"/health\"\n    protocol = \"HTTP\"\n    matcher = \"200\"\n    interval = 15\n    timeout = 5\n    healthy_threshold = 3\n    unhealthy_threshold = 3\n  }\n}\n\nresource \"aws_lb_listener_rule\" \"asg\" {\n  listener_arn = aws_lb_listener.http.arn\n  priority = 100\n\n  condition {\n    path_pattern {\n      values = [\"*\"]\n    }\n  }\n\n  action {\n    type = \"forward\"\n    target_group_arn = aws_lb_target_group.agenda_tg.arn\n  }\n}\n</code></pre> <p>Again, we are creating the same architecture we manually created in the previous sections. The load balancer will distribute the traffic among the instances created by the autoscaling group, and every time a new instance is created or destroyed, the load balancer will automatically adjust the traffic distribution.</p>"},{"location":"automated/terraform/#outputs","title":"Outputs","text":"<p>Finally, we define the outputs of the script. In this case, we are going to output the DNS name of the load balancer, so we can access the application.</p> <pre><code>output \"agenda_alb_dns_name\" {\n  value = aws_lb.agenda_lb\n  description = \"Domain name of the Agenda App ALB\"\n}\n</code></pre>"},{"location":"automated/terraform/#executing-the-terraform-script","title":"Executing the Terraform script","text":"<p>The first thing we need to do is to init the Terraform script. From the deploy <code>folder</code>, run:</p> <pre><code>terraform init .\n</code></pre> <p>It will download the required providers and configure the environment to run the script.</p> <p>You can validate the script with:</p> <pre><code>terraform validate\n</code></pre> <p>that will validate the syntax of the script. You should see something like:</p> <pre><code>Success! The configuration is valid.\n</code></pre> <p>Before we actually run the build process, note that we need to provide the AWS credentials to Terraform. You can do it by setting the environment variables:</p> <pre><code>export AWS_ACCESS_KEY_ID=your_access_key\nexport AWS_SECRET_ACCESS_KEY=your_secret_key\n</code></pre> <p>Now, we can see the plan of the script with:</p> <pre><code>terraform plan -var 'ami_id=&lt;your-ami-id&gt;'\n</code></pre> <p>This will show you the resources that are going to be created, updated, or destroyed. Note this is a dry-run, and no resources will be created or updated. The output should be something like:</p> <pre><code>deploy git:(main) \u2717 terraform plan\ndata.aws_vpc.default: Reading...\ndata.aws_vpc.default: Read complete after 5s [id=vpc-0f5918a8441f43e9d]\ndata.aws_subnets.default: Reading...\ndata.aws_subnets.default: Read complete after 0s [id=eu-south-2]\n\nTerraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols:\n  + create\n\nTerraform will perform the following actions:\n\n  # aws_autoscaling_group.agenda_asg will be created\n  + resource \"aws_autoscaling_group\" \"agenda_asg\" {\n      + arn                              = (known after apply)\n      + availability_zones               = (known after apply)\n      + default_cooldown                 = (known after apply)\n      + desired_capacity                 = 3\n      + force_delete                     = false\n      + force_delete_warm_pool           = false\n      + health_check_grace_period        = 300\n      + health_check_type                = \"ELB\"\n      + id                               = (known after apply)\n      + ignore_failed_scaling_activities = false\n      + load_balancers                   = (known after apply)\n      + max_size                         = 6\n      + metrics_granularity              = \"1Minute\"\n      + min_size                         = 2\n      + name                             = (known after apply)\n      + name_prefix                      = (known after apply)\n      + predicted_capacity               = (known after apply)\n      + protect_from_scale_in            = false\n      + service_linked_role_arn          = (known after apply)\n      + target_group_arns                = (known after apply)\n      + vpc_zone_identifier              = [\n          + \"subnet-050010bfc645b3a2e\",\n          + \"subnet-055234c6df6254488\",\n          + \"subnet-0be41289b68a0f06d\",\n        ]\n      + wait_for_capacity_timeout        = \"10m\"\n      + warm_pool_size                   = (known after apply)\n\n      + launch_template {\n          + id      = (known after apply)\n          + name    = (known after apply)\n          + version = (known after apply)\n        }\n\n      + mixed_instances_policy (known after apply)\n\n      + tag {\n          + key                 = \"Name\"\n          + propagate_at_launch = true\n          + value               = \"agenda-asg\"\n        }\n\n      + traffic_source (known after apply)\n    }\n\n  # aws_launch_template.agenda will be created\n  + resource \"aws_launch_template\" \"agenda\" {\n      + arn             = (known after apply)\n      + default_version = (known after apply)\n      + id              = (known after apply)\n      + instance_type   = \"t3.micro\"\n      + key_name        = \"mimo-cloud-teacher\"\n      + latest_version  = (known after apply)\n      + name            = \"agenda-template\"\n      + name_prefix     = (known after apply)\n      + tags_all        = (known after apply)\n        # (1 unchanged attribute hidden)\n\n      + block_device_mappings {\n          + device_name = \"/dev/sda1\"\n\n          + ebs {\n              + iops        = (known after apply)\n              + throughput  = (known after apply)\n              + volume_size = 20\n              + volume_type = \"gp2\"\n            }\n        }\n\n      + metadata_options (known after apply)\n\n      + network_interfaces {\n          + associate_public_ip_address = \"true\"\n          + security_groups             = (known after apply)\n        }\n\n      + tag_specifications {\n          + resource_type = \"instance\"\n          + tags          = {\n              + \"Name\" = \"agenda-app\"\n            }\n        }\n    }\n\n  # aws_lb.agenda_lb will be created\n  + resource \"aws_lb\" \"agenda_lb\" {\n      + arn                                                          = (known after apply)\n      + arn_suffix                                                   = (known after apply)\n      + client_keep_alive                                            = 3600\n      + desync_mitigation_mode                                       = \"defensive\"\n      + dns_name                                                     = (known after apply)\n      + drop_invalid_header_fields                                   = false\n      + enable_deletion_protection                                   = false\n      + enable_http2                                                 = true\n      + enable_tls_version_and_cipher_suite_headers                  = false\n      + enable_waf_fail_open                                         = false\n      + enable_xff_client_port                                       = false\n      + enforce_security_group_inbound_rules_on_private_link_traffic = (known after apply)\n      + id                                                           = (known after apply)\n      + idle_timeout                                                 = 60\n      + internal                                                     = (known after apply)\n      + ip_address_type                                              = (known after apply)\n      + load_balancer_type                                           = \"application\"\n      + name                                                         = \"agenda\"\n      + name_prefix                                                  = (known after apply)\n      + preserve_host_header                                         = false\n      + security_groups                                              = (known after apply)\n      + subnets                                                      = [\n          + \"subnet-050010bfc645b3a2e\",\n          + \"subnet-055234c6df6254488\",\n          + \"subnet-0be41289b68a0f06d\",\n        ]\n      + tags_all                                                     = (known after apply)\n      + vpc_id                                                       = (known after apply)\n      + xff_header_processing_mode                                   = \"append\"\n      + zone_id                                                      = (known after apply)\n\n      + subnet_mapping (known after apply)\n    }\n\n  # aws_lb_listener.http will be created\n  + resource \"aws_lb_listener\" \"http\" {\n      + arn                      = (known after apply)\n      + id                       = (known after apply)\n      + load_balancer_arn        = (known after apply)\n      + port                     = 80\n      + protocol                 = \"HTTP\"\n      + ssl_policy               = (known after apply)\n      + tags_all                 = (known after apply)\n      + tcp_idle_timeout_seconds = (known after apply)\n\n      + default_action {\n          + order = (known after apply)\n          + type  = \"fixed-response\"\n\n          + fixed_response {\n              + content_type = \"text/plain\"\n              + message_body = \"Page Not Found\"\n              + status_code  = \"404\"\n            }\n        }\n\n      + mutual_authentication (known after apply)\n    }\n\n  # aws_lb_listener_rule.asg will be created\n  + resource \"aws_lb_listener_rule\" \"asg\" {\n      + arn          = (known after apply)\n      + id           = (known after apply)\n      + listener_arn = (known after apply)\n      + priority     = 100\n      + tags_all     = (known after apply)\n\n      + action {\n          + order            = (known after apply)\n          + target_group_arn = (known after apply)\n          + type             = \"forward\"\n        }\n\n      + condition {\n          + path_pattern {\n              + values = [\n                  + \"*\",\n                ]\n            }\n        }\n    }\n\n  # aws_lb_target_group.agenda_tg will be created\n  + resource \"aws_lb_target_group\" \"agenda_tg\" {\n      + arn                                = (known after apply)\n      + arn_suffix                         = (known after apply)\n      + connection_termination             = (known after apply)\n      + deregistration_delay               = \"300\"\n      + id                                 = (known after apply)\n      + ip_address_type                    = (known after apply)\n      + lambda_multi_value_headers_enabled = false\n      + load_balancer_arns                 = (known after apply)\n      + load_balancing_algorithm_type      = (known after apply)\n      + load_balancing_anomaly_mitigation  = (known after apply)\n      + load_balancing_cross_zone_enabled  = (known after apply)\n      + name                               = \"agenda-tg\"\n      + name_prefix                        = (known after apply)\n      + port                               = 80\n      + preserve_client_ip                 = (known after apply)\n      + protocol                           = \"HTTP\"\n      + protocol_version                   = (known after apply)\n      + proxy_protocol_v2                  = false\n      + slow_start                         = 0\n      + tags_all                           = (known after apply)\n      + target_type                        = \"instance\"\n      + vpc_id                             = \"vpc-0f5918a8441f43e9d\"\n\n      + health_check {\n          + enabled             = true\n          + healthy_threshold   = 3\n          + interval            = 15\n          + matcher             = \"200\"\n          + path                = \"/health\"\n          + port                = \"traffic-port\"\n          + protocol            = \"HTTP\"\n          + timeout             = 5\n          + unhealthy_threshold = 3\n        }\n\n      + stickiness (known after apply)\n\n      + target_failover (known after apply)\n\n      + target_group_health (known after apply)\n\n      + target_health_state (known after apply)\n    }\n\n  # aws_security_group.agenda_alb will be created\n  + resource \"aws_security_group\" \"agenda_alb\" {\n      + arn                    = (known after apply)\n      + description            = \"Managed by Terraform\"\n      + egress                 = [\n          + {\n              + cidr_blocks      = [\n                  + \"0.0.0.0/0\",\n                ]\n              + from_port        = 0\n              + ipv6_cidr_blocks = []\n              + prefix_list_ids  = []\n              + protocol         = \"-1\"\n              + security_groups  = []\n              + self             = false\n              + to_port          = 0\n                # (1 unchanged attribute hidden)\n            },\n        ]\n      + id                     = (known after apply)\n      + ingress                = [\n          + {\n              + cidr_blocks      = [\n                  + \"0.0.0.0/0\",\n                ]\n              + from_port        = 80\n              + ipv6_cidr_blocks = []\n              + prefix_list_ids  = []\n              + protocol         = \"tcp\"\n              + security_groups  = []\n              + self             = false\n              + to_port          = 80\n                # (1 unchanged attribute hidden)\n            },\n        ]\n      + name                   = \"agenda-alb\"\n      + name_prefix            = (known after apply)\n      + owner_id               = (known after apply)\n      + revoke_rules_on_delete = false\n      + tags_all               = (known after apply)\n      + vpc_id                 = (known after apply)\n    }\n\n  # aws_security_group.instance will be created\n  + resource \"aws_security_group\" \"instance\" {\n      + arn                    = (known after apply)\n      + description            = \"Managed by Terraform\"\n      + egress                 = (known after apply)\n      + id                     = (known after apply)\n      + ingress                = [\n          + {\n              + cidr_blocks      = []\n              + from_port        = 80\n              + ipv6_cidr_blocks = []\n              + prefix_list_ids  = []\n              + protocol         = \"tcp\"\n              + security_groups  = (known after apply)\n              + self             = false\n              + to_port          = 80\n                # (1 unchanged attribute hidden)\n            },\n        ]\n      + name                   = \"agenda\"\n      + name_prefix            = (known after apply)\n      + owner_id               = (known after apply)\n      + revoke_rules_on_delete = false\n      + tags_all               = (known after apply)\n      + vpc_id                 = (known after apply)\n    }\n\nPlan: 8 to add, 0 to change, 0 to destroy.\n\nChanges to Outputs:\n  + agenda_alb_dns_name = {\n      + access_logs                                                  = []\n      + arn                                                          = (known after apply)\n      + arn_suffix                                                   = (known after apply)\n      + client_keep_alive                                            = 3600\n      + connection_logs                                              = []\n      + customer_owned_ipv4_pool                                     = null\n      + desync_mitigation_mode                                       = \"defensive\"\n      + dns_name                                                     = (known after apply)\n      + dns_record_client_routing_policy                             = null\n      + drop_invalid_header_fields                                   = false\n      + enable_cross_zone_load_balancing                             = null\n      + enable_deletion_protection                                   = false\n      + enable_http2                                                 = true\n      + enable_tls_version_and_cipher_suite_headers                  = false\n      + enable_waf_fail_open                                         = false\n      + enable_xff_client_port                                       = false\n      + enable_zonal_shift                                           = null\n      + enforce_security_group_inbound_rules_on_private_link_traffic = (known after apply)\n      + id                                                           = (known after apply)\n      + idle_timeout                                                 = 60\n      + internal                                                     = (known after apply)\n      + ip_address_type                                              = (known after apply)\n      + load_balancer_type                                           = \"application\"\n      + name                                                         = \"agenda\"\n      + name_prefix                                                  = (known after apply)\n      + preserve_host_header                                         = false\n      + security_groups                                              = (known after apply)\n      + subnet_mapping                                               = (known after apply)\n      + subnets                                                      = [\n          + \"subnet-050010bfc645b3a2e\",\n          + \"subnet-055234c6df6254488\",\n          + \"subnet-0be41289b68a0f06d\",\n        ]\n      + tags                                                         = null\n      + tags_all                                                     = (known after apply)\n      + timeouts                                                     = null\n      + vpc_id                                                       = (known after apply)\n      + xff_header_processing_mode                                   = \"append\"\n      + zone_id                                                      = (known after apply)\n    }\n\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\nNote: You didn't use the -out option to save this plan, so Terraform can't guarantee to take exactly these actions if you run \"terraform apply\" now.\n</code></pre> <p>If everything looks good, you can apply the script with:</p> <pre><code>terraform apply -var 'ami_id=&lt;your-ami-id&gt;'\n</code></pre> <p>This will show you the resources that are going to be created, updated, or destroyed. If everything looks good, type <code>yes</code> and hit enter. Terraform will start creating the resources.</p> <p>Have you suceeded? Can you access the application?</p>"},{"location":"database/connecting/","title":"Connecting to the RDS instance","text":"<p>This is identical to the previous section where we connected our application to a MySQL instance running on our local machine. The only difference is that now we are connecting to an RDS instance running on AWS.</p>"},{"location":"database/connecting/#updating-the-application-configuration","title":"Updating the application configuration","text":"<p>Connect to the EC2 instance where the Play application is running and open the <code>conf/application.conf</code> file. Update the <code>db</code> section of this configuration file with the connection details of the RDS instance. The configuration should look something like this:</p> <pre><code>db {\n  default.driver=com.mysql.cj.jdbc.Driver\n  default.url=\"jdbc:mysql://&lt;your-rds-instance-dns&gt;/agenda\"\n  default.username=\"&lt;your-username&gt;\"\n  default.password=\"&lt;your-password&gt;\"\n  # Provided for JPA access\n  default.jndiName=DefaultDS\n}\n</code></pre> <p>Please, make sure you use the values you have introduced during the creation of your RDS instance</p>"},{"location":"database/connecting/#testing-the-connection","title":"Testing the connection","text":""},{"location":"database/dependencies/","title":"Managing our database dependencies","text":"<p>If we want to use a database in our Play application, we need to add the necessary dependencies to our project. In this section, we'll learn how to add the necessary dependencies to our project to use a MySQL database.</p>"},{"location":"database/dependencies/#adding-the-mysql-dependency","title":"Adding the MySQL dependency","text":"<p>To use a MySQL database in our Play application, we need to add the MySQL connector dependency to our project. We can do this by adding the following dependency to our <code>build.sbt</code> file:</p> <pre><code>libraryDependencies ++= Seq(\n      // --- other dependencies ---\n      \"mysql\" % \"mysql-connector-java\" % \"8.0.33\" % \"runtime\",\n      // --- other dependencies ---\n    ),\n</code></pre> <p>Note that we don't require the MySQL connector to compile our application, so we added the dependency with the <code>runtime</code> scope. This means that the dependency will be available at runtime, but it won't be included in the compilation classpath. This dependency will provide the necessary classes to connect to a MySQL database.</p>"},{"location":"database/dependencies/#configuring-the-database-connection","title":"Configuring the database connection","text":"<p>To connect to a MySQL database, we need to configure the database connection in our <code>conf/application.conf</code> file. We need to provide the URL, username, and password to connect to the database. We can do this by adding the following configuration to our <code>conf/application.conf</code> file:</p> <pre><code>db {\n  default.driver=com.mysql.cj.jdbc.Driver\n  default.url=\"jdbc:mysql://root:root@localhost/agenda\"\n  default.username=\"root\"\n  default.password=\"root\"\n  # Provided for JPA access\n  default.jndiName=DefaultDS\n}\n</code></pre> <p>In this configuration, we are using the <code>com.mysql.cj.jdbc.Driver</code> driver to connect to the MySQL database. We are connecting to the <code>agenda</code> database running on <code>localhost</code> with the username <code>root</code> and password <code>root</code>. You should replace these values with the appropriate values for your MySQL database (the ones you set up in the previous steps).</p>"},{"location":"database/dependencies/#testing-the-database-connection","title":"Testing the database connection","text":"<p>Now that we have added the MySQL dependency and configured the database connection, we can run our Play application. Start your application and try to add some data to the database! Does it work? What happens if you restart the application? Do you lose the data you added?</p>"},{"location":"database/intro/","title":"Storing our data","text":"<p>The database is a crucial part of any application. It's where we store our data, and it's where we retrieve it from. In this section, we'll learn how to provision a production-ready database for our Play application.</p> <p>The Agenda application we are using in this guide is a simple application that stores and retrieved data from a database using JPA. We'll continue using this application to demonstrate how to provision a database.</p>"},{"location":"database/intro/#the-default-database","title":"The default database","text":"<p>Until now, we've been using an in-memory database for our application. This is fine for development, but it's not suitable for production. We need a database that can store our data permanently. What would happen if our application crashed? Or if we needed to scale it up? We would lose all our data.</p>"},{"location":"database/local-mysql/","title":"Connecting to MySQL locally","text":"<p>Before we jump into building a production-ready database in our cloud provider, let's explore what it takes to connect to a MySQL database locally. This will help us understand the different configurations we need to set up in our application to connect to such a database.</p>"},{"location":"database/local-mysql/#setting-up-mysql","title":"Setting up MySQL","text":"<p>The first thing we need to do is to install MySQL in our local environment. You can download MySQL from the official website. Follow the instructions to install MySQL in your local environment.</p> <p>If you are running macOS, you can use Homebrew to install MySQL. Run the following command to install MySQL:</p> <pre><code>brew install mysql\n</code></pre> <p>If you are running Linux, you can use the package manager of your distribution to install MySQL. For example, in Ubuntu, you can run the following command:</p> <pre><code>sudo apt install mysql-server\n</code></pre> <p>Ensure that MySQL is running in your local environment.</p> <pre><code>sudo systemctl start mysql.service\n</code></pre>"},{"location":"database/local-mysql/#configuring-the-user","title":"Configuring the user","text":"<p>You can use the <code>mysqladmin</code> command to configure the user you want to use to connect to the database. For the sake of this guide, we will use the <code>root</code> user. Run the following command to configure the <code>root</code> user:</p> <pre><code>mysqladmin -u root password 'root'\n</code></pre>"},{"location":"database/local-mysql/#creating-our-database-and-schema","title":"Creating our database and schema","text":"<p>Now that we have configured the user, we can create a database that we will use in our Play application. The first thing we need to do is to connect to the MySQL server using the <code>mysql</code> command-line client. Run the following command to connect to the MySQL server:</p> <pre><code>mysql -u root -p\n</code></pre> <p>and introduce the password you set up in the previous step.</p> <p>You should see a prompt where you can run SQL commands:</p> <pre><code>\u279c  agenda git:(master) \u2717 mysql -u root -p\nEnter password: \nWelcome to the MySQL monitor.  Commands end with ; or \\g.\nYour MySQL connection id is 10\nServer version: 9.0.1 Homebrew\n\nCopyright (c) 2000, 2024, Oracle and/or its affiliates.\n\nOracle is a registered trademark of Oracle Corporation and/or its\naffiliates. Other names may be trademarks of their respective\nowners.\n\nType 'help;' or '\\h' for help. Type '\\c' to clear the current input statement.\n\nmysql&gt; \n</code></pre> <p>The actual commands to create the database can be found in the apps/agenda/conf/sql/tables.sql</p> <pre><code>create database if not exists agenda default character set utf8 collate utf8_general_ci;\nuse agenda;\ncreate table if not exists Person (id int unsigned not null AUTO_INCREMENT, name VARCHAR(100) NOT NULL, PRIMARY KEY (id) );\n</code></pre> <p>Run the previous commands in the MySQL prompt to create the <code>agenda</code> database and our app's schema:</p> <pre><code>mysql&gt; create database if not exists agenda default character set utf8 collate utf8_general_ci;\nQuery OK, 1 row affected, 2 warnings (0.00 sec)\n\nmysql&gt; use agenda;\nDatabase changed\nmysql&gt; \nmysql&gt; create table if not exists Person (id int unsigned not null AUTO_INCREMENT, name VARCHAR(100) NOT NULL, PRIMARY KEY (id) );\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql&gt; \n</code></pre> <p>At this point, our database is ready to be used in our Play application. Remember the values you used to create the database, as we will need them to configure the database connection in our Play application.</p>"},{"location":"database/rds/","title":"Running a relational database in production","text":"<p>We started our journey by running our small Play application using an in-memory database. This was a great way to get started and get our application up and running quickly. However, in a real-world scenario, we would want to use a relational database to store our data. In this section, we'll learn how to run a relational database in production.</p> <p>In order to get familiar with the changes that need to be done, in the previous section we installed a MySQL database in our development environment, and connected our Play application to it. During the following sections, we will learn how to run a MySQL database in production using our Cloud provider.</p>"},{"location":"database/rds/#managed-services","title":"Managed services","text":"<p>You could think that installing MySQL in a production environment is as simple as running <code>sudo apt-get install mysql-server</code>. However, there are a few things to consider when running a database in production. We need to make sure that the database is secure, that it's properly configured, and that it's backed up regularly. This usually involves having certain level of expertise in running and maintaining a database.</p> <p>Fortunately, most Cloud providers offer managed database services that take care of all these things for us. In this section, we'll learn how to run a MySQL database in production using the managed database service provided by our Cloud provider: Amazon RDS.</p>"},{"location":"database/rds/#spawn-a-new-rds-instance","title":"Spawn a new RDS instance","text":"<p>The first step is to create a new RDS instance. To do this, we need to go to the AWS console and click on the <code>RDS</code> service. Once there, we need to click on the <code>Create database</code> button. This will open a wizard that will guide us through the process of creating a new RDS instance.</p> <p>Most of the settings are self-explanatory. We need to select the database engine we want to use (MySQL), the version of the engine, and the instance class (make sure you select the Free Tier here). We can leave the default settings for now. We need to provide a username and password to connect to the database. Make sure to store these credentials in a safe place.</p>"},{"location":"database/rds/#connectivity-from-our-play-application","title":"Connectivity from our Play application","text":"<p>In the previous wizard, we also need to configure the connectivity settings. We need to make sure that our Play application can connect to the database. We need to provide the security group that the RDS instance will use. Make sure to configure a security group that allows traffic from the instance where the Play application is running.</p>"},{"location":"database/rds/#connecting-to-the-rds-instance","title":"Connecting to the RDS instance","text":"<p>Once we have finished the wizard and the database is up and running (it takes a while), we can connect to the RDS instance using a MySQL client. We can use the <code>mysql</code> command line client to connect to the database. The connection string will look something like this:</p> <pre><code>mysql -h &lt;rds-endpoint&gt; -u &lt;username&gt; -p\n</code></pre> <p>If everything went well, we should be able to connect to the database and start running queries. Grab the contents of the <code>conf/sql/tables.sql</code> and run in the session we have just established:</p> <pre><code>create database if not exists agenda default character set utf8 collate utf8_general_ci;\nuse agenda;\ncreate table if not exists Person (id int unsigned not null AUTO_INCREMENT, name VARCHAR(100) NOT NULL, PRIMARY KEY (id) );\n</code></pre> <p>We are ready to connect our Play application to this very new database!</p>"},{"location":"iac/benefits/","title":"Benefits","text":"<p>The evolution of infrastructure management is fundamentally about democratization and empowerment. Self-service approaches break down traditional organizational silos, inviting everyone from developers to system administrators to actively participate in infrastructure design and deployment. This inclusive model transforms infrastructure from a restricted, specialized domain to a collaborative ecosystem where diverse expertise can contribute and innovate.</p> <p>At the heart of this transformation lies a dual commitment to safety and speed. By embracing infrastructure as code, organizations can achieve deployments that are simultaneously faster and more reliable. These deployments become consistent, repeatable, and significantly less error-prone, eliminating the variability and risk associated with manual interventions.</p> <p>Version control emerges as a critical enabler of this approach. By applying the same rigorous version tracking used in software development, teams gain unprecedented visibility and control. Every infrastructure change can be traced, debugged, and if necessary, rolled back to a previous state. Code reviews become a standard practice, ensuring quality and knowledge sharing across teams.</p> <p>The principle of reusability further amplifies these benefits. Just as software developers build complex applications from well-tested, composable modules, infrastructure teams can now construct robust, scalable systems using proven, modular components. This approach promotes efficiency, reduces redundancy, and accelerates innovation by allowing teams to build upon proven, reliable foundations.</p> <p>Ultimately, this approach represents more than a technological shift\u2014it's a cultural transformation that empowers teams, reduces risk, and accelerates organizational agility.</p>"},{"location":"iac/intro/","title":"Entering the infrastructure as code (IaC) world","text":"<p>We have performed a fully operational deploy of a highly available and scalable application. However, it's been a manual and error-prone process. What happens if we need to deploy a new environment? What if we need to scale up or down? What if we need to update the application? We need to automate the process. During this journey, we will learn how to treat infrastructure as code, how to automate the deployment process, and how to manage the infrastructure as a programmable, manageable resource.</p>"},{"location":"iac/types/","title":"Types of IaC tools","text":"<p>In the world of modern technology infrastructure, organizations are moving beyond manual, ad-hoc approaches to embrace a more systematic and automated strategy. This journey begins with custom scripts \u2013 practical solutions that automate repetitive tasks using languages like Bash, Python, or Ruby. These initial scripts represent the first step towards treating infrastructure as a programmable, manageable resource.</p> <p>As complexity grows, configuration management tools like Chef, Puppet, Ansible, and SaltStack emerge as sophisticated solutions. These tools go beyond simple scripting, providing robust mechanisms to install, manage, and maintain software across servers. They introduce crucial concepts like coding conventions and idempotence, ensuring consistent and predictable infrastructure deployments.</p> <p>Server templating takes this approach further by creating self-contained images that encapsulate everything from the operating system to specific software and required files. Tools like Docker, Vagrant, and Packer enable this approach, supporting two primary runtime environments: virtual machines and containers. This approach underpins the immutable infrastructure philosophy \u2013 once a server is deployed, it remains unchanged, reducing configuration drift and improving reliability.</p> <p>Orchestration becomes critical as these environments scale. Tools like Kubernetes, Nomad, Mesos, and AWS ECS handle the complex dynamics of modern infrastructure \u2013 deploying applications, rolling out updates, managing blue-green deployments, monitoring performance, and dynamically scaling resources. They transform infrastructure from static resources to adaptive, responsive ecosystems.</p> <p>Provisioning tools like Terraform, CloudFormation, and OpenStack complete this ecosystem by focusing on creating the underlying infrastructure itself. They go beyond traditional server provisioning, managing complex resources including load balancers, databases, caches, message queues, and monitoring systems.</p> <p>This evolution represents more than just technological change \u2013 it's a fundamental reimagining of how we conceive, create, and manage technological infrastructure. By treating infrastructure as code, organizations can achieve unprecedented levels of consistency, reliability, and scalability.</p>"},{"location":"iac/why/","title":"Why?","text":"<p>In the evolving landscape of technology infrastructure, a fundamental shift is transforming how organizations manage and deploy their systems. Historically, infrastructure deployment was the exclusive domain of operations teams, working through manual processes and siloed approaches. However, the rise of cloud computing has revolutionized this paradigm, blending the roles of software development and operations into a more integrated, code-driven discipline.</p> <p>Infrastructure as Code (IaC) represents this transformative approach, where infrastructure is no longer managed through manual configurations or traditional administrative tasks, but instead defined, deployed, updated, and decommissioned through sophisticated code-based methodologies. This approach enables teams to treat infrastructure with the same rigor, version control, and programmatic precision traditionally applied to software development.</p> <p>To measure the effectiveness of this approach, four critical metrics have emerged as key performance indicators for software delivery and operational excellence. These metrics provide a comprehensive view of an organization's technological agility and reliability:</p> <ul> <li>Delivery lead time tracks the speed of implementing, testing, and delivering changes to production, reflecting an organization's ability to rapidly respond to market needs.</li> <li>Deployment frequency measures how often changes are successfully pushed to production, indicating the team's capacity for continuous improvement and innovation.</li> <li>The change fail percentage reveals the reliability of these deployments by quantifying the proportion of changes that cause operational issues or require immediate correction.</li> <li>Finally, mean time to restore service assesses an organization's resilience by measuring how quickly systems can be recovered during unexpected disruptions.</li> </ul> <p>By embracing Infrastructure as Code, organizations can achieve greater consistency, reduce human error, enhance scalability, and create more responsive and reliable technological ecosystems.</p>"},{"location":"local/intro/","title":"Introduction","text":"<p>Our main goal is to learn how to deploy our application to the Cloud, but before we do that, we need to develop our application locally. In this section, we will learn how to set up our development environment, how to run our application locally, and how to test it.</p> <p>We will be using the Play Framework application included in the apps/agenda directory. This is a simple Play application that allows us to manage a list of contacts. The application has a REST API that allows us to create, and list contacts. It's not our goal to learn how to develop a Play application, since you should already be familiar with that. Our goal is to learn how to deploy it to the Cloud and put in practice the different concepts that will help us to deploy a fault-tolerant and scalable application.</p> <p>The Agenda application is a small Play application that uses JPA to store the contacts in a database. The application uses an in-memory H2 database, so we don't need to set up a database server to run the application. The application is already configured to use the H2 database, so we don't need to make any changes to the application. We will iterate over the application as we learn how to deploy it to the Cloud.</p>"},{"location":"local/running/","title":"Running our application locally","text":"<p>Since you have probably already set up your development environment during the first part of this subject, getting the Agenda application running in your local environment should be a no brainer for you. If you haven't done that yet, please refer to the Setting up your development environment official docs.</p> <p>Once you are ready, execute the application using the following command:</p> <pre><code>cd apps/agenda\nsbt run\n</code></pre> <p>The output should look like this:</p> <pre><code>\u279c  agenda git:(master) \u2717 sbt run  \n[info] welcome to sbt 1.10.2 (Eclipse Adoptium Java 17.0.13)\n[info] loading settings for project agenda-build from plugins.sbt ...\n[info] loading project definition from /Users/migue/development/sourcecode/migue/cloud-native/applications/agenda/project\n[info] loading settings for project root from build.sbt ...\n[info]   __              __\n[info]   \\ \\     ____   / /____ _ __  __\n[info]    \\ \\   / __ \\ / // __ `// / / /\n[info]    / /  / /_/ // // /_/ // /_/ /\n[info]   /_/  / .___//_/ \\__,_/ \\__, /\n[info]       /_/               /____/\n[info] \n[info] Version 3.0.6 running Java 17.0.13\n[info] \n[info] Play is run entirely by the community. Please consider contributing and/or donating:\n[info] https://www.playframework.com/sponsors\n[info] \n\n--- (Running the application, auto-reloading is enabled) ---\n\nINFO  p.c.s.PekkoHttpServer - Listening for HTTP on /[0:0:0:0:0:0:0:0]:9000\n\n(Server started, use Enter to stop and go back to the console...)\n</code></pre> <p>Go to your browser and open the following URL: http://localhost:9000. Does this work for you? If it does, congratulations! You have your application running locally.</p>"},{"location":"manual/deploy/","title":"Deploying the Play application","text":"<p>In order to deploy the Play application, we need to copy the application files to the instance. The application example we are using during this tutorial is a simple Play application located in the apps/agenda directory.</p> <p>Let's go ahead and build the application:</p> <pre><code>cd apps/agenda\nsbt dist\n</code></pre> <p>This will create a zip file in the <code>target/universal</code> directory. Now we need to copy this file to the instance. We can use the <code>scp</code> command to do this:</p> <pre><code>scp -i /path/to/keypair.pem target/universal/agenda-1.0-SNAPSHOT.zip ubuntu@&lt;instance-ip&gt;:/home/ubuntu\n</code></pre> <p>Once the file is copied, we can connect to the instance and unzip the file:</p> <pre><code>ssh -i /path/to/keypair.pem ubuntu@&lt;instance-ip&gt;\nunzip agenda-1.0-SNAPSHOT.zip\n</code></pre>"},{"location":"manual/instance/","title":"Creating an EC2 instance","text":"<p>The first step is to create an EC2 instance. To do this, we need to go to the AWS console and click on the <code>EC2</code> service. Once there, we need to click on the <code>Launch Instance</code> button. This will open a wizard that will guide us through the process of creating a new instance. Make sure to select the latest Ubuntu Server LTS version and an instance type that's included in the free tier.</p> <p>We can leave the default settings for now. As we progress through the wizard, we will be asked to create a new key pair. This key pair will be used to connect to the instance via SSH. Make sure to download the key pair and store it in a safe place.</p> <p>At this point we should have a new instance running. We can connect to it via SSH using the key pair we created earlier. The SSH command will look something like this:</p> <pre><code>ssh -i /path/to/keypair.pem\n</code></pre>"},{"location":"manual/instance/#installing-the-necessary-software","title":"Installing the necessary software","text":"<p>Once we are connected to the instance, we need to install the necessary software to run our Play application. This means we need to install, at least, the Java runtime. We </p> <pre><code>sudo apt-get update &amp;&amp; sudo apt upgrade\nsudo apt-get install openjdk-17-jdk-headless unzip\n</code></pre>"},{"location":"manual/intro/","title":"Introduction","text":"<p>During this section we will learn how to use the AWS graphical interface to create a virtual machine and install the necessary software to run a Play application.</p>"},{"location":"manual/running/","title":"Running the Play application","text":"<p>We are ready to run our application for the first time. Go into your application folder and run the following command:</p> <pre><code>sudo ./bin/agenda -Dhttp.port=80 -Dplay.http.secret.key=\"9gx9[jnPE&gt;zTDmzAC^p&lt;ETbLBsnljKEqhT1CSDDDYubCw?4^agPJX:2Rz1k2?h&lt;AaUB\"\n</code></pre> <p>A couple of things to note here which are particularly tight to the Play framework:</p> <p>If you look at your <code>conf/application.conf</code> file, you will find a configuration section that looks like this:</p> <p><pre><code># Allowed hosts\nplay.filters.hosts {\n  # Allow requests to example.com, its subdomains, and localhost:9000.\n  allowed = [\".amazonaws.com\", \"localhost:9000\"]\n}\n</code></pre> when you deploy a Play application you need to properly configure the <code>play.filters.hosts.allowed</code> configuration to allow requests from the domain you are deploying the application to. In this case, we are deploying the application to an AWS instance, so we need to allow requests from the AWS domain.</p> <p>The <code>play.http.secret.key</code> configuration is used to signing session cookies and CSRF tokens and built in encryption utilities. It is important to keep this value secret and unique for each application. You can generate a new secret key by running the following command:</p> <pre><code>sbt playGenerateSecret\n</code></pre> <p>The application should now be running and accessible via the instance's public IP address. What has happened? Did it work for your? In case it didn't, what do think we need to do to fix it?</p>"},{"location":"manual/running/#fixing-our-deployment","title":"Fixing our deployment","text":"<p>As you have already probably noticed, the application is not accessible from the outside world. This is because the Play application is running on port 80, but the instance's security group is not allowing traffic on that port.</p> <p>Go back to the AWS console and click on the <code>Security Groups</code> link. Select the security group associated with the instance and click on the <code>Edit inbound rules</code> button. Add a new rule that allows traffic on port 80 from anywhere.</p> <p>What would happen if we restart the instance? Would the application still be running? What do you think we need to do to make sure the application is always running? Let's try to figure it out together.</p>"},{"location":"manual/running/#always-running","title":"Always running","text":"<p>As we mentioned earlier, the application will stop running if the instance is restarted. To make sure the application is always running, we need to use a process manager like <code>systemd</code>.</p> <p>In our AWS instance, we need to create a new service file in the <code>/etc/systemd/system</code> directory. Let's create a new file called <code>agenda.service</code>:</p> <pre><code>sudo vim /etc/systemd/system/agenda.service\n</code></pre> <p>with the following content:</p> <pre><code>[Unit]\nDescription=\"Agenda Play application\"\n\n[Service]\nWorkingDirectory=/home/ubuntu/agenda-1.0-SNAPSHOT\nExecStart=\nExecStop=/bin/kill -TERM $MAINPID\nType=simple\nRestart=always\n\n[Install]\nWantedBy=multi-user.target\n</code></pre> <p>Now we need to reload the systemd daemon and start the service:</p> <pre><code>sudo systemctl daemon-reload\nsudo systemctl enable agenda\n</code></pre> <p>What would happen if you kill the process? Or if the application crashes? What would happen if the instance is restarted? You can try to simulate these scenarios and see what happens.</p>"},{"location":"manual/running/#checking-the-status-of-the-service","title":"Checking the status of the service","text":"<p>You can check the status of the service by running:</p> <pre><code>sudo systemctl status agenda\n</code></pre> <p>and you can check the logs of the application by running:</p> <pre><code>sudo journalctl -u agenda\n</code></pre> <p>The output of the previous command should look something similar to:</p> <pre><code>ubuntu@ip-172-31-4-87:~/agenda-1.0-SNAPSHOT$ journalctl -u agenda -f\nDec 13 18:17:56 ip-172-31-4-87 agenda[2438]: INFO  p.c.s.PekkoHttpServer - Running provided shutdown stop hooks\nDec 13 18:17:56 ip-172-31-4-87 systemd[1]: agenda.service: Main process exited, code=exited, status=143/n/a\nDec 13 18:17:56 ip-172-31-4-87 systemd[1]: agenda.service: Failed with result 'exit-code'.\nDec 13 18:17:56 ip-172-31-4-87 systemd[1]: Stopped agenda.service - \"Agenda Play application\".\nDec 13 18:17:56 ip-172-31-4-87 systemd[1]: agenda.service: Consumed 18.591s CPU time, 63.6M memory peak, 0B memory swap peak.\nDec 13 18:18:04 ip-172-31-4-87 systemd[1]: Started agenda.service - \"Agenda Play application\".\nDec 13 18:18:06 ip-172-31-4-87 agenda[2558]: INFO  p.a.h.HttpErrorHandlerExceptions - Registering exception handler: guice-provision-exception-handler\nDec 13 18:18:07 ip-172-31-4-87 agenda[2558]: INFO  p.a.d.DefaultDBApi - Database [default] initialized\nDec 13 18:18:07 ip-172-31-4-87 agenda[2558]: INFO  p.a.d.HikariCPConnectionPool - Creating Pool for datasource 'default'\nDec 13 18:18:07 ip-172-31-4-87 agenda[2558]: INFO  p.a.d.HikariCPConnectionPool - datasource [default] bound to JNDI as DefaultDS\nDec 13 18:18:12 ip-172-31-4-87 agenda[2558]: INFO  play.api.Play - Application started (Prod) (no global state)\nDec 13 18:18:12 ip-172-31-4-87 agenda[2558]: INFO  p.c.s.PekkoHttpServer - Listening for HTTP on /[0:0:0:0:0:0:0:0]:80\n</code></pre>"},{"location":"scaling/ami/","title":"Making a snapshot of our setup","text":"<p>Now that we have our application fully configured and running on an EC2 instance, we can create an snapshot. This will allow us to create new instances with the same configuration as the one we have now. This is useful if we want to scale our application both horizontally and vertically. In both scenarios, we can create new instances based on the snapshot we are about to create.</p>"},{"location":"scaling/ami/#building-an-amazon-machine-image-ami","title":"Building an Amazon Machine Image (AMI)","text":"<p>In AWS, these snapshots are called AMIs (Amazon Machine Image). They are a special type of virtual appliance that is used to create a virtual machine within the Amazon Elastic Compute Cloud (EC2). It serves as the basic unit of deployment for services delivered using EC2.</p> <p>Creating an AMI is a simple process. We just need to go to the AWS console and click on the <code>EC2</code> service. Once there, we need to click on the <code>Instances</code> link. This will show us a list of all the instances we have running. We need to select the instance we want to create an AMI from and click on the <code>Actions</code> button. From the dropdown menu, we need to select the <code>Image and templates</code> option and then click on the <code>Create image</code> button.</p> <p>You can find all your AMIs by clicking on the <code>AMIs</code> link in the <code>Images</code> section of the EC2 service.</p>"},{"location":"scaling/ami/#spawning-a-new-instance-from-the-ami","title":"Spawning a new instance from the AMI","text":"<p>Once the AMI is created, we can spawn a new instance from it. To do this, we need to go to the AWS console and click on the <code>EC2</code> service. Once there, we need to click on the <code>Launch Instance</code> button. This will open a wizard that will guide us through the process of creating a new instance. This time, instead of selecting the latest Ubuntu Server LTS version, we need to select the <code>My AMIs</code> option. This will show us a list of all the AMIs we have created. We need to select the one we just created and follow the wizard to create a new instance (don't forget to use the free tier instance type).</p> <p>Now we have a new instance running with the same configuration as the one we created the AMI. Now we can take more concurrent requests and serve more users, and we can do it in a matter of seconds! And not only that, we can also create new instances with the same configuration in different regions, making our application more resilient to failures.</p>"},{"location":"scaling/ami/#open-questions","title":"Open questions","text":"<p>How do we offer a seamless experience to our users when we are scaling our application? What do you think we need to do to make sure that our users don't notice that we are scaling our application? Let's try to figure it out together.</p>"},{"location":"scaling/intro/","title":"Scale and fault-tolerance","text":"<p>At this point we have our Play application running on an EC2 instance, connected to a MySQL database runnning as an RDS instance. But now we want to make sure our application can handle more traffic and that it's fault-tolerant.</p> <p>What happens if our application crashes? What happens if the instance is restarted? How can we make sure our application is always running and can handle more traffic? </p> <p>During the next sections we will answer all these questions, and more</p>"},{"location":"scaling/loadbalancing/","title":"Making our deployment resilient","text":"<p>As me mentioned earlier, we would like to provide a seamless experience when we are scaling our application. This means that we need to make sure our users are not aware of any change we make to our deployment architecture: adding new instances, removing old ones, using a different region or availability zone, using a different instance type, etc. All these are internal details that should not be visible to our users.</p>"},{"location":"scaling/loadbalancing/#introduction-to-load-balancing","title":"Introduction to load balancing","text":"<p>One of the most common ways to make our deployment resilient is by using a load balancer. A load balancer is a layer (hardware or software) that distributes network or application traffic across a cluster of servers. Load balancers are used to increase capacity (concurrent users) and reliability of applications. They improve the overall performance of applications by distributing the workload across multiple servers, ensuring that no single server is overwhelmed.</p> <p>AWS provides a service called Elastic Load Balancing (ELB) that automatically distributes incoming application traffic across multiple targets, such as Amazon EC2 instances. It can handle the varying load of your application traffic in a single Availability Zone or across multiple Availability Zones.</p>"},{"location":"scaling/loadbalancing/#creating-a-load-balancer","title":"Creating a load balancer","text":"<p>Let's create a load balancer for our application. To do this, we need to go to the AWS console and click on the <code>EC2</code> service. Once there, we need to click on the <code>Load Balancers</code> section.</p> <p>Once there, we need to click on the <code>Create Load Balancer</code> button. This will open a wizard that will guide us through the process of creating a new load balancer. At the time of writing, there are three types of load balancers available: Application Load Balancer, Network Load Balancer, and Gateway Load Balancer. The previous generation load balancers (Classic Load Balancer) are available too.bWe are not going to deep dive into the differences between them, but we are going to use the Application Load Balancer.</p> <p>Pick the Application Load Balancer and click on the <code>Create</code> button. This will open a new wizard where we need to configure the load balancer. We need to provide a name for the load balancer, a scheme (internet-facing), an IP address type (IPv4). In the network settings section, select our unique VPC and all the availabilty zones available.</p> <p>In the security group settings, we need to create a new security group that allows traffic on port 80 from anywhere.</p> <p>In the Listeners and routing section, we need to configure the listener. A listener is a process that checks for connection requests using the port and protocol you configure. We need to configure the listener to listen on port 80 and define the default action for routing requests.</p> <p>We will need to create a new target group. A target group is used to route requests to one or more registered targets. We need to provide a name for the target group, a protocol (HTTP), a port (80), and the target type (instance). We need to register the instances we want to route traffic to. The target group also specifies the health checks that need to be performed on the targets to determine their health status.</p> <p>Don't forget to register the instances we want to route traffic to before hitting the <code>Create Target Group</code> button.</p>"},{"location":"scaling/loadbalancing/#health-checks-and-play","title":"Health checks and Play","text":"<p>The target group we created will perform health checks on the instances we registered. The health checks are used to determine the health status of the instances. If an instance is unhealthy, the load balancer will stop routing traffic to it. ALB health checks don't send a Host header in the request, so we need to make sure our Play application is configured to accept requests without a Host header. This is a bit unusual, as the HTTP specification requires the Host header to be present in all requests.</p> <p>In order to configure a proper health endpoint in our Play application, we need to define a new <code>anyhost</code> tag, which can be used to exclude one or more routes from the <code>AllowedHostsFilter</code>.</p> <pre><code>play.filters.hosts.routeModifiers.whiteList = [anyhost]\n</code></pre> <p>Now, we can configure our health check route in our <code>conf/routes</code> file:</p> <pre><code>+anyhost\nGET     /health                     controllers.HealthCheckController.check()\n</code></pre> <p>If we run our application and try to hit the <code>/health</code> endpoint with an empty <code>Host</code> header, we should get a <code>200 OK</code> response.</p> <pre><code>&gt; curl -I -H 'Host:' http://localhost:9000/health\nHTTP/1.1 200 OK\nReferrer-Policy: origin-when-cross-origin, strict-origin-when-cross-origin\nX-Frame-Options: DENY\nX-XSS-Protection: 1; mode=block\nX-Content-Type-Options: nosniff\nX-Permitted-Cross-Domain-Policies: master-only\ncontent-length: 7\nContent-Type: text/plain; charset=utf-8\nDate: Sat, 14 Dec 2024 23:30:57 GMT\n</code></pre> <p>However, if we hit the <code>/persons</code> endpoint, we should get a <code>400</code> error back</p> <pre><code>curl -I -H 'Host:' http://localhost:9000/persons\nHTTP/1.1 400 Bad Request\nReferrer-Policy: origin-when-cross-origin, strict-origin-when-cross-origin\nX-Frame-Options: DENY\nX-XSS-Protection: 1; mode=block\nX-Content-Type-Options: nosniff\nX-Permitted-Cross-Domain-Policies: master-only\ncontent-length: 1166\nContent-Type: text/html; charset=utf-8\nDate: Sat, 14 Dec 2024 23:32:03 GMT\n</code></pre>"},{"location":"scaling/loadbalancing/#validating-our-load-balancer","title":"Validating our load balancer","text":"<p>At this point, our system is ready! If an instance becomes unhealthy, the load balancer will stop routing traffic to it. If we add more instances, the load balancer will automatically start routing traffic to them. We can now scale our application horizontally and vertically without our users noticing any change. Let's try to hit the load balancer's DNS name and see if we get a response back.</p>"}]}